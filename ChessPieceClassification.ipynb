{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e81561f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting split-folders\n",
      "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
      "Installing collected packages: split-folders\n",
      "\u001b[33m  WARNING: The scripts split-folders, split_folders and splitfolders are installed in '/Users/Maximus/Library/Python/3.9/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed split-folders-0.5.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2bcf6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04f47a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da411fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n",
      "unzip:  cannot find or open /LinearAlgebraProject/ChessPiecesDataset.zip, /LinearAlgebraProject/ChessPiecesDataset.zip.zip or /LinearAlgebraProject/ChessPiecesDataset.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/davidmallasen/LiveChess2FEN/releases/download/v0.1.0/ChessPiecesDataset.zip\n",
    "\n",
    "!unzip /LinearAlgebraProject/ChessPiecesDataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74b04fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The provided input folder \"/content/ChessPiecesDataset\" does not exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/93/wqm2t5z95wl_jtxhrqw5mnh80000gn/T/ipykernel_11024/300457717.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplitfolders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msplitfolders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/ChessPiecesDataset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/splitfolders/split.py\u001b[0m in \u001b[0;36mratio\u001b[0;34m(input, output, seed, ratio, group_prefix, move)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`ratio` should\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_input_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_tqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/splitfolders/split.py\u001b[0m in \u001b[0;36mcheck_input_format\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mp_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_absolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf' Your relative path cannot be found from the current working directory \"{Path.cwd()}\".'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mp_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The provided input folder \"/content/ChessPiecesDataset\" does not exists."
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "splitfolders.ratio('/content/ChessPiecesDataset', output = \"output\", seed = 1, ratio = (.8, .1, .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6d12dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_dir = '/content/output/'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce20977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "batch_size = 256\n",
    "opt = SGD(learning_rate=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811a3416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# randomly rotate the images to allow the model to learn variations in orientation\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=5,\n",
    "        # width_shift_range=0.1,\n",
    "        # height_shift_range=0.1,\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from os import path\n",
    "# Define the stopping callbacks\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc11fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (224, 224)\n",
    "train_gen = datagen.flow_from_directory(train_dir, target_size = shape, batch_size = batch_size, class_mode = 'categorical', color_mode = 'rgb', shuffle=True)\n",
    "valid_gen = test_datagen.flow_from_directory(validation_dir, target_size = shape, batch_size = batch_size, class_mode = 'categorical', color_mode = 'rgb', shuffle=False)\n",
    "test_gen = test_datagen.flow_from_directory(test_dir, target_size = shape, batch_size = batch_size, class_mode = 'categorical', color_mode = 'rgb', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3fef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.densenet import DenseNet201\n",
    "\n",
    "shape = (224, 224)\n",
    "train_gen = datagen.flow_from_directory(train_dir, target_size = shape, batch_size = batch_size, class_mode = 'categorical', color_mode = 'rgb', shuffle=True)\n",
    "valid_gen = test_datagen.flow_from_directory(validation_dir, target_size = shape, batch_size = batch_size, class_mode = 'categorical', color_mode = 'rgb', shuffle=False)\n",
    "test_gen = test_datagen.flow_from_directory(test_dir, target_size = shape, batch_size = batch_size, class_mode = 'categorical', color_mode = 'rgb', shuffle=False)\n",
    "\n",
    "base_model = DenseNet201(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
    "# Freeze convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False    \n",
    "\n",
    "# Establish new fully connected block\n",
    "x = base_model.output\n",
    "x = Flatten()(x)  # flatten from convolution tensor output  \n",
    "x = Dense(1000, activation='relu')(x) # number of layers and units are hyperparameters, as usual\n",
    "predictions = Dense(13, activation='softmax')(x) # should match # of classes predicted\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d029d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "if os.path.exists('model_DenseNet201.h5'):\n",
    "    model = tf.keras.models.load_model('model_DenseNet201.h5')\n",
    "    print(\"Model loaded\")\n",
    "    history = model.fit(\n",
    "    train_gen, \n",
    "    epochs=epochs,\n",
    "    verbose = 1,\n",
    "    validation_data=test_gen,\n",
    "    callbacks = [es]\n",
    "    )\n",
    "    model.save('model_DenseNet201.h5') \n",
    "else:\n",
    "    history = model.fit(\n",
    "        train_gen, \n",
    "        epochs=epochs,\n",
    "        verbose = 1,\n",
    "        validation_data=test_gen,\n",
    "        callbacks = [es]\n",
    "        )\n",
    "    model.save('model_DenseNet201.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c05549",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model_DenseNet201.h5')\n",
    "_, acc = model.evaluate(valid_gen, verbose=0)\n",
    "print('> %.3f' % (acc * 100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
